from collections import OrderedDict
import json
import sys
from tableschema import Schema
from etl.helpers import table_schema

# Target names
MISSION_IMPACT = "mi"
PATHWAYS = "pathways"
PROGRAMS = "programs"

IS_ADMIN_FIELD = "IS_ADMIN_FIELD"

JSON_PATH = "json_path"
ADMIN_JSON_PATH = "admin_json_path"
MARKDOWN_PATH = "markdown_path"
NAME = "name"

# TODO: Use pkg_resources instead of relative paths.
MISSION_IMPACT_INFO = {
    JSON_PATH: "etl/schemas/mission_impact_table_schema.json",
    MARKDOWN_PATH: "etl/schemas/MISSION_IMPACT.md",
    NAME: "Mission Impact",
}
PATHWAYS_INFO = {
    JSON_PATH: "etl/schemas/pathways_schema.json",
    MARKDOWN_PATH: "datasheets/PATHWAYS.md",
    NAME: "Google Pathways",
}
PROGRAMS_INFO = {
    JSON_PATH: "etl/schemas/programs_schema.json",
    MARKDOWN_PATH: "datasheets/PROGRAMS.md",
    NAME: "Programs",
}

# Converts datasheet (in markdown table format) to validator (in json format).
#
# Target indicates which markdown to create. Valid values: 'mi', 'pathways', 'programs'
def generate_markdown(target):

    # Get information for target.
    if target == MISSION_IMPACT:
        target_info = MISSION_IMPACT_INFO
    elif target == PATHWAYS:
        target_info = PATHWAYS_INFO
    elif target == PROGRAMS:
        target_info = PROGRAMS_INFO
    else:
        raise Exception("Invalid target: " + target)

    # Load schema.
    schema = Schema(target_info[JSON_PATH])

    filename = "```" + target_info[JSON_PATH] + "```"

    # Add title and description for datasheet.'
    markdown = "Data Sheet for " + target_info[NAME] + " Data"
    markdown += "\n==================================\n\n"
    markdown += (
        "The description of required and recommended fields for "
        + target_info[NAME]
        + " data follows.\n\n"
    )
    markdown += (
        "**Note**: DO NOT edit this file directly. This file was generated from "
        + filename
        + ".<br>"
    )
    markdown += (
        "To edit this file, make changes to "
        + filename
        + " and run (from the repo root) "
    )
    markdown += (
        "```python -m scripts.generate_datasheets "
        + target
        + "``` to re-generate this file.\n\n"
    )

    if target == MISSION_IMPACT:
        markdown += "To derive the column-based name/key from the API Key listed here, the default is to add "
        markdown += "the milestone flag as a prefix (i.e. `IntakeDate`, `ExitDate`, `NinetyDaysDate`). However, some "
        markdown += "fields do not use this naming convention (i.e. `IntakeCurrentMostRecentJobLastDayOfWork` and "
        markdown += "`ExitJobPlacementStartDate` for `JobDate`). For fields that differ from the default naming convention, "
        markdown += "the names are listed in the `Custom Milestone Names` column of this datasheet.\n\n"

        # Mission impact datasheet has additional columns, so provide viewing instructions.
        markdown += "If your mouse does not allow horizontal scroll, click on the table and use the "
        markdown += "left/right arrow keys to view all columns.\n\n"

    # Add table header. For mission impact data, there is an additional column for milestones.
    markdown += "| Data Field | API Key | Required | Data Type | Accepts Multiple Values | Accepted Values |"
    markdown += (
        " Milestones | Custom Milestone Names |\n" if target == MISSION_IMPACT else "\n"
    )

    markdown += "| ---------- | ------- | -------- | --------- | ----------------------- | --------------- |"
    markdown += " ----------- | ------- |\n" if target == MISSION_IMPACT else "\n"

    for field in schema.fields:

        allows_multiple = (
            "allows_multiple" in field.descriptor.keys()
            and field.descriptor["allows_multiple"]
        )

        # Enum fields can be "String Enum" or "Integer Enum" based on whether they are converted to int value in pipeline.
        is_enum = (
            "enum" in field.constraints.keys()
            or "enum_mapping" in field.descriptor.keys()
        )
        data_type = field.type.capitalize() + ("" if not is_enum else " Enum")

        # Extract fields from json entry.
        row = [
            field.descriptor["title"],
            field.name,
            str(field.required),
            data_type,
            str(allows_multiple),
        ]

        if "enum_mapping" in field.descriptor.keys():
            row.append(
                "<br>".join(
                    [
                        str(num) + " = " + s
                        for s, num in field.descriptor["enum_mapping"].items()
                    ]
                )
            )
        elif "enum" in field.constraints.keys():
            row.append("<br>".join(field.constraints["enum"]))
        elif "minimum" in field.constraints.keys():
            row.append(
                str(field.constraints["minimum"])
                + ", "
                + str(field.constraints["maximum"])
            )
        elif field.name == "SOC":
            # SOC has custom range.
            row.append("11-0000, 53-7199")
        else:
            row.append("")

        # Add milestone and custom milestone names field for mission impact datasheet.
        if target == MISSION_IMPACT:
            MISSION_IMPACT_MILESTONES = table_schema.get_milestone_names(schema)

            if "milestones" in field.descriptor.keys():
                row.append(
                    ", ".join(
                        [
                            MISSION_IMPACT_MILESTONES[i]
                            for i in field.descriptor["milestones"]
                        ]
                    )
                )
            else:
                row.append("")

            if "custom_milestone_field_names" in field.descriptor.keys():
                name_mapping = field.descriptor["custom_milestone_field_names"]
                # Example - "Intake: `IntakeCurrentMostRecentJobLastDayOfWork` <br> Exit: `ExitJobPlacementStartDate`"
                row.append(
                    "<br>".join(
                        [
                            MISSION_IMPACT_MILESTONES[int(k)]
                            + ": `"
                            + name_mapping[k]
                            + "`"
                            for k in sorted(name_mapping.keys())
                        ]
                    )
                )
            else:
                row.append("")

        # Add row to markdown table.
        markdown += "|" + "|".join(row) + "|\n"

    # Write datasheet file.
    with open(target_info[MARKDOWN_PATH], "wb") as f:
        f.write(markdown.encode("utf8"))


# By default, this generates all three markdown files (mission impact, and programs)
# and writes the outputs to the datasheets folder. To only generate select files,
# use arguments 'mi', 'pathways', and 'programs'.
#
# For example, to only generate the mission impact datasheet, run this command:
#
#   generate_datasheets.py mi
#
def main():
    # Run all if no arguments.
    run_all = len(sys.argv) == 1

    if run_all or MISSION_IMPACT in sys.argv:
        generate_markdown(MISSION_IMPACT)
    if run_all or PATHWAYS in sys.argv:
        generate_markdown(PATHWAYS)
    if run_all or PROGRAMS in sys.argv:
        generate_markdown(PROGRAMS)


if __name__ == "__main__":
    main()
